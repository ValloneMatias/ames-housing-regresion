{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43a2c6c",
   "metadata": {},
   "source": [
    "üè† Proyecto: Predicci√≥n de Precios de Casas (Ames Housing ‚Äì OpenML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ 1. Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• 2. Cargar el dataset desde OpenML\n",
    "ames = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "df = ames.frame\n",
    "\n",
    "print(\"Dimensiones:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d71466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3: Variable Objetivo\n",
    "# Vamos a predecir el precio final de venta\n",
    "target = \"SalePrice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a61d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4: Limpieza de datos\n",
    "\n",
    "# 1. Eliminar columnas con m√°s del 30% de nulos (y hacer copia)\n",
    "umbral_nulos = 0.3\n",
    "df = df.loc[:, df.isnull().mean() < umbral_nulos].copy()  # ‚Üê Agregamos .copy()\n",
    "\n",
    "# 2. Rellenar categ√≥ricas con la moda\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# 3. Rellenar num√©ricas con la mediana\n",
    "for col in df.select_dtypes(include=[\"int64\", \"float64\"]).columns:\n",
    "    df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99843684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5: Codificaci√≥n y separaci√≥n\n",
    "\n",
    "# One-hot encoding para las variables categ√≥ricas\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Separar X e y\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d0a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Divisi√≥n de datos y escalado\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Selecci√≥n autom√°tica de features\n",
    "selector = SelectKBest(score_func=f_regression, k=50)\n",
    "X_train_sel = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_sel = selector.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Entrenamiento y evaluaci√≥n de modelos\n",
    "\n",
    "modelos = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    modelo.fit(X_train_sel, y_train)\n",
    "    pred = modelo.predict(X_test_sel)\n",
    "\n",
    "    resultados[nombre] = {\n",
    "        \"MAE\": mean_absolute_error(y_test, pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, pred)),\n",
    "        \"R2\": r2_score(y_test, pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ed28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Visualizaci√≥n de resultados\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados).T\n",
    "df_resultados.plot(kind=\"bar\", figsize=(10, 5))\n",
    "plt.title(\"Comparaci√≥n de Modelos\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Analisis visual del rendimiento de los modelos\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Obtener predicciones para an√°lisis visual\n",
    "y_pred_rf = modelos[\"Random Forest\"].predict(X_test_sel)\n",
    "y_pred_lr = modelos[\"Linear Regression\"].predict(X_test_sel)\n",
    "y_pred_xgb = modelos[\"XGBoost\"].predict(X_test_sel)\n",
    "\n",
    "# === 1. Comparar valores reales vs. predichos ===\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred_rf, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Precio Real\")\n",
    "plt.ylabel(\"Precio Predicho\")\n",
    "plt.title(\"Random Forest - Precio Real vs. Predicho\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Distribuci√≥n de los errores (residuos) ===\n",
    "errores_rf = y_test - y_pred_rf\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(errores_rf, bins=30, kde=True)\n",
    "plt.title(\"Distribuci√≥n de errores - Random Forest\")\n",
    "plt.xlabel(\"Error (real - predicho)\")\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Gr√°fico de residuos vs. valor predicho ===\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(x=y_pred_rf, y=errores_rf, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Precio Predicho\")\n",
    "plt.ylabel(\"Error (real - predicho)\")\n",
    "plt.title(\"Residuos vs. Predicci√≥n - Random Forest\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6d5a1",
   "metadata": {},
   "source": [
    "üîö Conclusiones:\n",
    "En este proyecto se compararon tres modelos de regresi√≥n multivariable aplicados al dataset Ames Housing, evaluando su capacidad para predecir el precio de las viviendas.\n",
    "\n",
    "Luego del preprocesamiento, selecci√≥n de caracter√≠sticas y entrenamiento, los resultados mostraron que:\n",
    "\n",
    "Random Forest fue el modelo con mejor rendimiento global, logrando el menor error (RMSE) y el mayor coeficiente de determinaci√≥n (R¬≤).\n",
    "\n",
    "XGBoost obtuvo resultados similares, siendo una excelente alternativa, especialmente en contextos con mayor volumen de datos.\n",
    "\n",
    "Regresi√≥n Lineal present√≥ el rendimiento m√°s bajo, aunque sigue siendo valiosa como punto de partida para comparar modelos m√°s complejos.\n",
    "\n",
    "Los gr√°ficos de an√°lisis de rendimiento (precio real vs. predicho, distribuci√≥n de errores y residuos vs. predicci√≥n) confirmaron la estabilidad y precisi√≥n del modelo Random Forest, sin sesgos evidentes ni errores sistem√°ticos.\n",
    "\n",
    "Este pipeline puede mejorarse y ampliarse con:\n",
    "\n",
    "Optimizaci√≥n de hiperpar√°metros (por ejemplo, mediante GridSearchCV o RandomizedSearchCV),\n",
    "\n",
    "Validaci√≥n cruzada para obtener m√©tricas m√°s robustas,\n",
    "\n",
    "T√©cnicas de interpretabilidad (como SHAP o importancia de variables),\n",
    "\n",
    "Exportaci√≥n del modelo final (joblib o pickle) para su reutilizaci√≥n."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
